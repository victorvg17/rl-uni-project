{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rl_runs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Iskd_heHKhXJ"
      },
      "outputs": [],
      "source": [
        "# connect G-drive\n",
        "# To save to google drive and run on colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QSfp5C_gLVS9"
      },
      "outputs": [],
      "source": [
        "# copy files to run-time machine from google gdrive\n",
        "!cp gdrive/My\\ Drive/Colab\\ Notebooks/rl\\ project/* .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oIMVmvkHLwFW"
      },
      "outputs": [],
      "source": [
        "# install ConfigSpace\n",
        "!pip install ConfigSpace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vuqcpJcIxvij"
      },
      "outputs": [],
      "source": [
        "# Function to save results in gdrive in order to have them after each run\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "folders = ['models', 'results', 'config']\n",
        "\n",
        "def import2drive():\n",
        "  save_parent = Path('./content').resolve().parent /'gdrive' / 'My Drive' / 'Colab Notebooks' / 'rl project'\n",
        "  Path.is_dir(save_parent)\n",
        "  for folder in folders:\n",
        "    save_dir = save_parent / folder\n",
        "    Path.mkdir(save_dir, parents=True, exist_ok=True)\n",
        "    dirpath = Path('./content').resolve().parent / folder\n",
        "    print(dirpath)\n",
        "    for x in dirpath.iterdir():\n",
        "        print(x)\n",
        "        if x.is_file():\n",
        "          shutil.copy(str(dirpath/x), save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "eko1Wih5s2Z3"
      },
      "outputs": [],
      "source": [
        "# check arg parser arguments and possible configurations\n",
        "!python arg_parser.py -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ih_buMcZ0_Ai"
      },
      "outputs": [],
      "source": [
        "# Defining Hyperparameters to be used in ConfigSpace\n",
        "gamma = 0.99\n",
        "cont_act_dim = 1\n",
        "float_hyper = {'epsilon': [0,1], 'trace_decay': [0,1], 'alpha': [0.00001, 0.1],'entropy_coeff':[0.0001, 0.1]}\n",
        "\n",
        "cat_hyper = {\"episode\": [1000, 2000, 3000, 4000], 'steps': [250, 500, 750], 'timesteps':[200,300,400,500,600],\\\n",
        "             'update_timesteps':[128,256,512,1024,2048], 'K_epochs': [5,10,15,20], 'eps_clip':[0.1,0.2,0.3,0.4,0.5],\\\n",
        "             'action_std': [0.1,0.2,0.3,0.4], 'hidden_unit':[32,64,128,256], 'reward_func': ['sparse','carrot', 'laplace','slow_rotation'],\\\n",
        "             'action_dim': [3,5,7]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GYrQqph8sMCM"
      },
      "outputs": [],
      "source": [
        "\n",
        "import ConfigSpace as CS\n",
        "import ConfigSpace.hyperparameters as CSH\n",
        "\n",
        "cs = CS.ConfigurationSpace(seed=1)\n",
        "# Actor learning rate\n",
        "cs.add_hyperparameter(CSH.UniformFloatHyperparameter(name='a_lr', lower=1e-4, upper=1e-1, default_value=1e-3, log=True))\n",
        "# Critic Learning rate\n",
        "cs.add_hyperparameter(CSH.UniformFloatHyperparameter(name='c_lr', lower=1e-4, upper=1e-1, default_value=1e-3, log=True))\n",
        "\n",
        "for k, v in float_hyper.items():\n",
        "  cs.add_hyperparameter(CSH.UniformFloatHyperparameter(name=k, lower=v[0], upper=v[1]))\n",
        "for w, z in cat_hyper.items():\n",
        "  cs.add_hyperparameter(CSH.CategoricalHyperparameter(name=w, choices=z))\n",
        "cs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GYSifDyosTX1"
      },
      "outputs": [],
      "source": [
        "# Run REINFORCE Discrete\n",
        "from utils import save_config_colab\n",
        "rounds = 1\n",
        "for i in range(rounds):\n",
        "  sample = cs.sample_configuration()\n",
        "  print(f'__starting round {i}')\n",
        "  for item in sample.get_dictionary().items():\n",
        "    print(item)\n",
        "  save_config_colab(sample.get_dictionary(), i, 'REINFORCE_discrete')\n",
        "  episode = sample.get('episode') # -e\n",
        "  reward = sample.get('reward_func') # -rw\n",
        "  action_dim = sample.get('action_dim') # -ac\n",
        "  timesteps = sample.get('timesteps') # -s\n",
        "  hidden_unit = sample.get('hidden_unit') # -hd\n",
        "  a_lr = sample.get('a_lr') # -alr\n",
        "  c_lr = sample.get('c_lr') # -clr\n",
        "\n",
        "  !python run_reinforce_discrete.py -e $episode -rw $reward -ac $action_dim -s $timesteps -hd $hidden_unit -alr $a_lr -clr $c_lr -ec $i\n",
        "  # import2drive()\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wSoGrN3fcJVM"
      },
      "outputs": [],
      "source": [
        "## Run PPO Continues\n",
        "from utils import save_config_colab\n",
        "rounds = 1\n",
        "for i in range(rounds):\n",
        "  sample = cs.sample_configuration()\n",
        "  print(f'__starting round {i}')\n",
        "  for item in sample.get_dictionary().items():\n",
        "    print(item)\n",
        "  save_config_colab(sample.get_dictionary(), i, 'PPO_Continues')\n",
        "  episode = sample.get('episode') # -e\n",
        "  reward = sample.get('reward_func') # -rw\n",
        "  action_dim = sample.get('action_dim') # -ac\n",
        "  timesteps = sample.get('timesteps') # -s\n",
        "  hidden_unit = sample.get('hidden_unit') # -hd\n",
        "  a_lr = sample.get('a_lr') # -alr\n",
        "  c_lr = sample.get('c_lr') # -clr\n",
        "  k_ep = sample.get('K_epochs') # -ke\n",
        "  action_std = sample.get('action_std') # -ad \n",
        "  entropy_coeff = sample.get('entropy_coeff') # -eco\n",
        "  epsilon_clip = sample.get('eps_clip') # -ecp\n",
        "  update_timesteps = sample.get('update_timesteps') # -us\n",
        "\n",
        "  !python run_ppo_continuous.py -e $episode -s $timesteps -rw $reward -hd $hidden_unit -alr $a_lr -clr $c_lr -ke $k_ep -ad $action_std -eco $entropy_coeff  -ecp $epsilon_clip -us $update_timesteps\n",
        "  # import2drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yOGBQhN5qFv_"
      },
      "outputs": [],
      "source": [
        "# Run REINFORCE continues\n",
        "from utils import save_config_colab\n",
        "rounds = 1\n",
        "for i in range(rounds):\n",
        "  sample = cs.sample_configuration()\n",
        "  print(f'__starting round {i}')\n",
        "  for item in sample.get_dictionary().items():\n",
        "    print(item)\n",
        "  save_config_colab(sample.get_dictionary(), i, 'REINFORCE_continues')\n",
        "  episode = sample.get('episode') # -e\n",
        "  reward = sample.get('reward_func') # -rw\n",
        "  action_dim = sample.get('action_dim') # -ac\n",
        "  timesteps = sample.get('timesteps') # -s\n",
        "  hidden_unit = sample.get('hidden_unit') # -hd\n",
        "  a_lr = sample.get('a_lr') # -alr\n",
        "  c_lr = sample.get('c_lr') # -clr\n",
        "\n",
        "  !python run_reinforce_continous.py -e $episode -rw $reward -ac $cont_act_dim -s $timesteps -hd $hidden_unit -alr $a_lr -clr $c_lr -ec $i\n",
        "  # import2drive()\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-MUnUfOcqwY7"
      },
      "outputs": [],
      "source": [
        "## Run PPO discrete\n",
        "from utils import save_config_colab\n",
        "rounds = 1\n",
        "for i in range(rounds):\n",
        "  sample = cs.sample_configuration()\n",
        "  print(f'__starting round {i}')\n",
        "  for item in sample.get_dictionary().items():\n",
        "    print(item)\n",
        "  save_config_colab(sample.get_dictionary(), i, 'PPO_discrete')\n",
        "  episode = sample.get('episode') # -e\n",
        "  reward = sample.get('reward_func') # -rw\n",
        "  action_dim = sample.get('action_dim') # -ac\n",
        "  timesteps = sample.get('timesteps') # -s\n",
        "  hidden_unit = sample.get('hidden_unit') # -hd\n",
        "  a_lr = sample.get('a_lr') # -alr\n",
        "  c_lr = sample.get('c_lr') # -clr\n",
        "  k_ep = sample.get('K_epochs') # -ke\n",
        "  action_std = sample.get('action_std') # -ad \n",
        "  entropy_coeff = sample.get('entropy_coeff') # -eco\n",
        "  epsilon_clip = sample.get('eps_clip') # -ecp\n",
        "  update_timesteps = sample.get('update_timesteps') # -us\n",
        "\n",
        "  !python run_ppo_discrete.py -ec $i -ac $action_dim -e $episode -s $timesteps -rw $reward -hd $hidden_unit -alr $a_lr -clr $c_lr -ke $k_ep -ad $action_std -eco $entropy_coeff  -ecp $epsilon_clip -us $update_timesteps\n",
        "  # import2drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rOj1Bw-PqxKg"
      },
      "outputs": [],
      "source": [
        "## Run DDPG continuous\n",
        "from utils import save_config_colab\n",
        "rounds = 21\n",
        "relevant_params = ['episode', 'timesteps', 'reward_func', 'hidden_unit', 'action_std', 'a_lr', 'c_lr']\n",
        "for i in range(16, rounds):\n",
        "  sample = cs.sample_configuration()\n",
        "  print(f'__starting round {i}')\n",
        "  for rel_param in relevant_params:\n",
        "    print(f'{rel_param}: {sample.get(rel_param)}')\n",
        "\n",
        "  save_config_colab(sample.get_dictionary(), i, 'DDPG_continuous')\n",
        "  episode = sample.get('episode') # -e\n",
        "  reward = sample.get('reward_func') # -rw\n",
        "  timesteps = sample.get('timesteps') # -s\n",
        "  hidden_unit = sample.get('hidden_unit') # -hd\n",
        "  a_lr = sample.get('a_lr') # -alr\n",
        "  c_lr = sample.get('c_lr') # -clr\n",
        "  action_std = sample.get('action_std') # -ad \n",
        "\n",
        "  !python run_ddpg_continuous.py -ec $i -e $episode -s $timesteps -rw $reward -hd $hidden_unit -alr $a_lr -clr $c_lr -ad $action_std\n",
        "  import2drive()"
      ]
    }
  ]
}